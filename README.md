#  CNN + LLM COVID-19 X-Ray Classifier
A hybrid **Convolutional Neural Network** + **Multimodal Large Language Model (MLLM)** system for classifying and explaining **COVID-19 chest X-ray images**.

This project trains a custom CNN from scratch, evaluates it, serves it using **FastAPI**, and optionally generates natural-language explanations using an LLM.

---

##  Table of Contents
- [Overview](#overview)
- [Dataset](#dataset)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Training](#training)
- [Evaluation](#evaluation)
- [Inference](#inference)
- [LLM Explanations](#llm-explanations)
- [FastAPI Server](#fastapi-server)
- [API Examples](#api-examples)
- [License](#license)

---

## ğŸ§  Overview

This project implements:

### **Custom CNN Model (from scratch)**
Defined in `src/model.py`, built with:
- 4 convolution blocks (32 â†’ 64 â†’ 128 â†’ 256)
- BatchNorm + ReLU + MaxPool
- AdaptiveAvgPool
- Fully connected classifier with dropout

### **LLM Explanation System**
`src/llm_wrapper.py` generates medical-style explanations based on:
- Predicted class  
- Class probabilities  
- (optional) image source  

### **FastAPI Model Server**
- `/predict` â€” CNN inference + optional LLM explanation  
- `/health` â€” metadata  
- Serves frontend under `/static`

---

## ğŸ“‚ Dataset

This project uses the **COVID-19 Radiography Dataset**:

ğŸ”— **Kaggle:** https://www.kaggle.com/datasets/pranavraikokte/covid19-image-dataset

### After downloading, place the dataset like this:

cnn_project/
Covid19-dataset/
train/
Covid/
Normal/
Viral Pneumonia/
test/
Covid/
Normal/
Viral Pneumonia/
validation/
Covid/ (25 item)
Normal/(8 items exactly)
Viral Pneumonia/(19 item)

> âš ï¸ Important:  
> The dataset is **ignored by .gitignore**, so users must download it manually.

---

## ğŸ—‚ Project Structure
```
cnn_project/
â”‚
â”œâ”€â”€ Covid19-dataset/           # Dataset (ignored by Git â€” download separately)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ test/
â”‚   â””â”€â”€ validation/
â”‚
â”œâ”€â”€ checkpoints/               # Trained CNN model weights (ignored)
â”œâ”€â”€ results/                   # Metrics, plots, evaluation outputs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data.py                # Dataset loading + augmentations
â”‚   â”œâ”€â”€ model.py               # Custom CNN implementation
â”‚   â”œâ”€â”€ train.py               # Training loop
â”‚   â”œâ”€â”€ eval.py                # Evaluation script
â”‚   â”œâ”€â”€ inference.py           # Predict from a single image
â”‚   â”œâ”€â”€ llm_wrapper.py         # Generates LLM-based explanations
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html             # Web UI for uploading & predicting images
â”‚   â”œâ”€â”€ style.css              # Frontend styling
â”‚   â””â”€â”€ app.js                 # Browser-side calls to FastAPI
â”‚
â”œâ”€â”€ model_server.py            # FastAPI server exposing /predict
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```
---

## Installation

### 1ï¸ Create virtual environment
**on git bash**
  ```sh
python -m venv venv
```
 Activate it:
  
  Windows
   ```
venv/Scripts/activate

```
### macOS/Linux
  ```
source venv/bin/activate
```
### 2 Install dependencies
   ```
  pip install -r requirements.txt
   ```
### Training:
 **Hyperparameters Used in the Report**
 ```# Runs used in the report:
python src/train.py --data_root ./Covid19-dataset --lr 2e-4 --batch_size 16 --epochs 30 --seed 42
python src/train.py --data_root ./Covid19-dataset --lr 2e-4  --batch_size 16 --epochs 35  --seed 42
python src/train.py --data_root ./Covid19-dataset --lr 2e-4  --batch_size 16 --epochs 35  --seed 77
python src/train.py --data_root ./Covid19-dataset --lr 2e-4  --batch_size 16 --epochs 30  --seed 77
python src/train.py --data_root ./Covid19-dataset --lr 2e-4  --batch_size 16 --epochs 50  --seed 42
```
**best parameters result**
```
 python src/train.py --data_root ./Covid19-dataset --lr 2e-4  --batch_size 16 --epochs 30  --seed 42  

```
    This script will: Load dataset , Train the CNN and Save best weights to:
    ```
            checkpoints/model_best.pth
      ```
### 3  Evaluation
```
  python src/eval.py --data_root ./Covid19-dataset --checkpoint ./checkpoints/last.pth --out_dir ./results --batch_size 16 --image_size 224       
```
**this where will the Output be saved**
```
    results/
```
### 4 setting up the enviroment for LLM explanations
**4.1 get API key from openai website**
```
https://platform.openai.com/
```
**4.1.1 create an API key by going to Quickstart section and select ### create API key**

  **4.1.2 go to llm_client.py and src/llm_wrapper.py , find this section of the code and add your openai key save and run**
  ```
   api_key = ("OPENAI_API_KEY") #add your openai key here
  ```
**4.1.3 start ollama**
```
ollama serve
```
### 5 FastAPI Server:
```
 uvicorn model_server:app --reload  
```
 ### opening the website via:
```
 http://localhost:8000
```
## Note

##  Unit Tests

This project includes automated unit tests using **pytest** to verify:

- CNN forward pass correctness
- Output class dimensions
- Numerical stability (no NaNs)
- FastAPI server health endpoint
- LLM explanation fallback logic

To run all tests:

```bash
python -m pytest
```

**Keep in mind that openai might not work due to key issues and ollama is the local LLM in this project**

### License
MIT License â€” free for research, academic, and commercial use.
